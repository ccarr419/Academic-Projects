# Name:			Christian Carreras
# File:			countAtomic2.stm
# Date:			10/17/2016
# Course:		CSC343 Kutztown University
# Professor:	Dr. Parson
# Assignment:	2
# About:		This file imitates a state machine where atomic locks are used to
#				prevent multiple threads from modifying the same data asynchronously. 
#				Two threads are trying to fetch memory into a register, do a
#				mathematical function on the register, and store the register back
#				into memory. To synchronize the threads this will be done
#				atomically by the use of a spin lock. Spin locks will ensure
#				that only one thread will compute the critical section code
#				at a time while the others wait until it is finished.
#				A waiting thread will loop back (spin) into the same state
#				until the lock is open.

machine processor {
    # STUDENT: Do not change the processor state machine.
    # Use this machine in all of your files in assignment 2 to fork
    # 1 process that runs many threads.
    start init, accept processorDone ;
    init -> processorDone init()[]/@
        fork()@
}

# STUDENT work goes into machine thread according to the handout.
# Add documentation comments for the code that you write!!!
machine thread {
    # You probably need to create additional variables.
    # When the iterations to the transition to go into the terminated state
    # increment loopCount to >= loopLimit, go to terminated.
    loopCount = 0, loopLimit = 10, sumRegister = 0, differenceRegister = 0,
        threadCount = 2,
        # Adjust loopGrandTotal to loopLimit * threadCount in init ->.
        loopGrandTotal = 0 ;
    start init, state initThreads,
        state fetchSum, state addSum, state storeSum,
        state fetchDifference, state addDifference, state storeDifference,
        state lockSum, state unlockSum,
        state lockDifference, state unlockDifference,
        accept terminated ;
		
    # Start the simulation rolling.
    init -> initThreads init()[]/@
        machineID, pid, tid = getid();
        cpu(1)@
		
    # STUDENT: Initialize the pcb HERE before spwaning any other threads.
	# Initialize all locks to open.
    initThreads -> lockSum cpu()[@tid == 0@]/@
        loopGrandTotal = loopLimit * threadCount ;
        pcb.sharedSum = 0 ;
        pcb.sharedDifference = 0 ;
		pcb.atomicAddLock = 0;
		pcb.atomicSubLock = 0;
        spawn();
        cpu(3)@
		
    # All but the final thread spawns its successor.
    initThreads -> lockSum cpu()[@tid > 0 and tid < (threadCount-1)@]/@
        spawn();
        cpu(1)@
		
    # All but the final thread spawns its successor.
    initThreads -> lockSum cpu()[@tid == (threadCount-1)@]/@
        cpu(3)@
		
    # Fetch sum into register after locking the atomic or mutex.
    lockSum -> fetchSum cpu()[@pcb.atomicAddLock == 0@]/@
		pcb.atomicAddLock = 1;
        sumRegister = pcb.sharedSum ;
        cpu(1)@
	
	# Loop back to same state until the lock opens (spin lock).
	lockSum -> lockSum cpu()[@pcb.atomicAddLock == 1@]/@
		cpu(3)@
		
    # Add 1 to the sum in the register.
    fetchSum -> addSum cpu()[]/@
        sumRegister += 1 ;
        cpu(1)@
    # store the register back into regular memory via the pcb.
    addSum -> storeSum cpu()[]/@
        pcb.sharedSum = sumRegister ;
        cpu(1)@
    # release the atomic spin lock or mutex
    storeSum -> unlockSum cpu()[]/@
		pcb.atomicAddLock = 0;
        cpu(3)@
    # NOW DO THE EQUIVALENT FOR DIFFERENCE
    unlockSum -> lockDifference cpu()[]/@
        cpu(3)@
		
    # Fetch difference into register after locking the atomic or mutex.
    lockDifference -> fetchDifference cpu()[@pcb.atomicSubLock == 0@]/@
		pcb.atomicSubLock = 1;
        differenceRegister = pcb.sharedDifference ;
        cpu(1)@
	
	# Loop back to same state until the lock opens (spin lock).
	lockDifference -> lockDifference cpu()[@pcb.atomicSubLock == 1@]/@
		cpu(3)@	
		
    # Add 1 to the difference in the register.
    fetchDifference -> addDifference cpu()[]/@
        differenceRegister -= 1 ;
        cpu(1)@
		
    # store the register back into regular memory via the pcb.
    addDifference -> storeDifference cpu()[]/@
        pcb.sharedDifference = differenceRegister ;
        cpu(1)@
		
    # release the atomic spin lock or mutex
    storeDifference -> unlockDifference cpu()[]/@
		pcb.atomicSubLock = 0;
        cpu(3)@
		
    # Do cycle again until loopLimit is hit.
    unlockDifference -> lockSum cpu()[@(loopCount+1) < loopLimit@]/@
        loopCount += 1 ;
        cpu(3)@
		
    unlockDifference -> terminated cpu()[@(loopCount+1) == loopLimit@]/@
        msg("ENDTHREAD," + str(tid) + ",SHAREDSUM," + str(pcb.sharedSum)
            + ",SHAREDDIFF," + str(pcb.sharedDifference))@
}

processor

